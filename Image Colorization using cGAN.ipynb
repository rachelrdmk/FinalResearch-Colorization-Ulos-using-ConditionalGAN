{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGE COLORIZATION USING cGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Contents**\n",
    "\n",
    "1. [Import Packages](#packages)\n",
    "2. [Utils](#utils)\n",
    "3. [Data preparation](#dataset)\n",
    "4. [Image Colorization and Color Science Computation](#4-image-colorization-and-color-science-computations)\n",
    "5. [Generator architecture](#generator)\n",
    "6. [Discriminator architecture](#discriminator)\n",
    "7. [Trainer](#training)\n",
    "8. [Validation](#validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Packages <a class=\"anchor\" id=\"packages\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\.conda\\envs\\ulos\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "c:\\Users\\Lenovo\\.conda\\envs\\ulos\\lib\\site-packages\\colour\\utilities\\verbose.py:265: ColourWarning: \"vaab/colour\" was detected in \"sys.path\", please define a \"COLOUR_SCIENCE__COLOUR__IMPORT_VAAB_COLOUR=True\" environment variable to import its objects into \"colour\" namespace!\n",
      "  warn(*args, **kwargs)  # noqa: B028\n"
     ]
    }
   ],
   "source": [
    "# Operating system and file operations\n",
    "import os\n",
    "\n",
    "# Numerical operations and array processing\n",
    "import numpy as np\n",
    "\n",
    "# Data visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Random number generation\n",
    "import random\n",
    "\n",
    "# Image processing and computer vision\n",
    "import cv2\n",
    "\n",
    "# Deep learning and neural networks\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Data handling for deep learning\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Displaying model information\n",
    "from torchsummary import summary\n",
    "\n",
    "# Image manipulation\n",
    "from PIL import Image\n",
    "\n",
    "# Type annotations\n",
    "from typing import List\n",
    "\n",
    "# Progress bar for Jupyter Notebooks\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Color space conversions\n",
    "from colour import sRGB_to_XYZ, XYZ_to_Lab, Lab_to_XYZ, XYZ_to_sRGB\n",
    "\n",
    "# Image quality assessment\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# Memory management\n",
    "import gc\n",
    "\n",
    "# Handling warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Utils <a class=\"anchor\" id=\"utils\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Determine the device to use for PyTorch operations\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Print the selected device which device will be used for PyTorch operations.\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Device Configuration for PyTorch\n",
    "\n",
    "The script determines and prints the computing device to be used for PyTorch operations based on hardware availability:\n",
    "\n",
    "1. **Determine the Device**: The code checks if a CUDA-enabled GPU is available. If yes, it sets the device to `'cuda'` to enable GPU acceleration. If not, it defaults to `'cpu'`.\n",
    "2. **Print Device Information**: It then prints the chosen device (`'cuda'` or `'cpu'`) to the console. This confirmation is useful for verifying that the intended hardware (GPU or CPU) is set for executing the operations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data preparation process is a crucial step in ensuring the quality and effectiveness of the image colorization model.\n",
    "\n",
    "#### Dataset Description\n",
    "- **Total Images**: 64 images.\n",
    "- **Image Formats**: Each image is available in two versions: grayscale and color.\n",
    "- **Image Resolution**: The images have been processed to a consistent resolution, suitable for model processing.\n",
    "\n",
    "#### Data Split\n",
    "The dataset has been divided into two main subsets for training and testing the model:\n",
    "- **Training Data**: 80% of the total images (51 images) are used for model training. The training data includes a mix of grayscale and color images, allowing the model to learn to recognize and reproduce colors from grayscale images.\n",
    "- **Testing Data**: 20% of the total images (13 images) are used as a test set to evaluate the model's performance. Testing ensures that the model can generalize what it has learned to new, unseen images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Image Colorization and Color Science Computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script is designed to handle the image colorization process using deep learning frameworks in PyTorch. It details the steps from dataset preparation, transformations, to model inference and visualization:\n",
    "\n",
    "1. **Color Space Conversion Functions**: Includes a function `lab_to_rgb` that converts images from the LAB color space to RGB using the torch and colour libraries. This function processes a batch of images for display or further processing.\n",
    "\n",
    "2. **Image Transformations**: Defines transformations to resize and normalize images. These transformations prepare images for consistent processing and improve model training efficiency.\n",
    "\n",
    "3. **Custom Dataset Class**: `ImageColorizeDataset` is a PyTorch dataset class that handles loading and preprocessing of images. It splits images into input and output parts, applies transformations, and adjusts the data format for model processing.\n",
    "\n",
    "4. **Data Loaders**: Set up for both training and testing, facilitating the easy batching of data for processing by the model.\n",
    "\n",
    "5. **Model Training and Inference Setup**: Orchestrates the flow from loading data, applying transformations, making predictions with the model, and preparing the images for visualization.\n",
    "\n",
    "6. **Visualization**: Displays a grid of original and colorized images using matplotlib, demonstrating the effectiveness of the model in a visual format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lab_to_rgb_save(L, ab, device, save_dir=\"./output\"):\n",
    "    \"\"\"\n",
    "    Takes a batch of images\n",
    "    \"\"\"\n",
    "    L = 100 * L  # Scale the L component from 0-1 to 0-100\n",
    "    ab = (ab - 0.5) * 256  # Adjust the a and b components to the correct range\n",
    "    Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).detach().cpu().numpy()  # Combine L, a, b, and rearrange the format for processing\n",
    "    rgb_imgs = []  # Initialize a list to store the resulting RGB images\n",
    "\n",
    "    rgb_imgs = []  # Initialize a list to store the resulting RGB images\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    for idx, img in enumerate(Lab):\n",
    "        img = Lab_to_XYZ(img)  # Assuming Lab_to_XYZ returns correctly formatted data\n",
    "        img = XYZ_to_sRGB(img)  # Assuming XYZ_to_sRGB returns correctly formatted data\n",
    "\n",
    "        if img.ndim != 3 or img.shape[2] not in [3, 4]:\n",
    "            raise ValueError(f\"Image format error: Expected shape (H, W, 3) or (H, W, 4), got {img.shape}\")\n",
    "\n",
    "        plt.imsave(os.path.join(save_dir, f\"image_{idx}.png\"), img.clip(0, 1))\n",
    "\n",
    "        rgb_imgs.append(img)\n",
    "    # for img in Lab:\n",
    "    #     img = Lab_to_XYZ(img)  # Convert LAB to XYZ\n",
    "    #     img = XYZ_to_sRGB(img)  # Convert XYZ to RGB\n",
    "    #     rgb_imgs.append(img)  # Append the RGB image to the list\n",
    "    return torch.tensor(np.stack(rgb_imgs, axis=0)).permute(0, 3, 1, 2).to(device)  # Return the images as a PyTorch tensor and move to the specified device\n",
    "\n",
    "def lab_to_rgb(L, ab, device):\n",
    "    \"\"\"\n",
    "    Takes a batch of images\n",
    "    \"\"\"\n",
    "    L = 100 * L  # Scale the L component from 0-1 to 0-100\n",
    "    ab = (ab - 0.5) * 256  # Adjust the a and b components to the correct range\n",
    "    Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).detach().cpu().numpy()  # Combine L, a, b, and rearrange the format for processing\n",
    "    rgb_imgs = []  # Initialize a list to store the resulting RGB images\n",
    "    for img in Lab:\n",
    "        img = Lab_to_XYZ(img)  # Convert LAB to XYZ\n",
    "        img = XYZ_to_sRGB(img)  # Convert XYZ to RGB\n",
    "        rgb_imgs.append(img)  # Append the RGB image to the list\n",
    "    return torch.tensor(np.stack(rgb_imgs, axis=0)).permute(0, 3, 1, 2).to(device)  # Return the images as a PyTorch tensor and move to the specified device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LAB to RGB Conversion Function\n",
    "\n",
    "The `lab_to_rgb` function is designed to convert images from the LAB color space to the RGB color space, facilitating the display or further processing of these images in more commonly used formats. The function operates on batches of images, enhancing processing efficiency. Here is a breakdown of the key operations within the function:\n",
    "\n",
    "1. **Normalization and Scaling**: \n",
    "   - The lightness component `L` is normalized from a range of 0-1 to 0-100.\n",
    "   - The color components `a` and `b` are scaled from a centered zero range (-0.5 to 0.5) to their full potential range (0 to 256).\n",
    "\n",
    "2. **Tensor Manipulation**: \n",
    "   - The `L`, `a`, and `b` components are concatenated into a single tensor and rearranged to match the expected input structure for color space conversion functions.\n",
    "\n",
    "3. **Color Space Conversion**:\n",
    "   - Each image in the batch is individually converted from LAB to XYZ, and then from XYZ to the standard sRGB space.\n",
    "\n",
    "4. **Tensor Preparation and Device Allocation**:\n",
    "   - The resulting RGB images are stacked into a single tensor, rearranged to match the expected input format of PyTorch operations, and transferred to the specified computational device (`cpu` or `gpu`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the desired image size\n",
    "image_size = (256, 128)\n",
    "\n",
    "# Compose a series of transformations to be applied to the images\n",
    "t = transforms.Compose([\n",
    "    transforms.Resize(image_size, antialias=True),  # Resize the image with antialias to reduce distortion\n",
    "    transforms.Normalize(mean=0, std=0.5)           # Normalize the images to facilitate neural network processing\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Data Transformations\n",
    "\n",
    "The image data transformation process involves setting the size and normalizing to prepare images for model training processes:\n",
    "\n",
    "1. **Size Adjustment**: Images are resized to 256 pixels in width and 128 pixels in height. The use of antialiasing helps to reduce moire effects and maintain clarity of the images after resizing.\n",
    "\n",
    "2. **Normalization**: Images are normalized with a mean of 0 and a standard deviation of 0.5. This normalization ensures that the image data has a uniform range of values, which is important for the stability and efficiency of deep learning model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageColorizeDataset(Dataset):\n",
    "    def __init__(self, path: str, device='cpu', train: bool = False, transforms = None):\n",
    "        # Set the dataset mode based on the train argument, 'train' for training and 'test' for testing\n",
    "        _mode = 'train' if train else 'test'\n",
    "        \n",
    "        self.device = device  # Device where data will be processed (CPU or GPU)\n",
    "        self._input_path = os.path.join(path, f'{_mode}_color')  # Path to the data\n",
    "        \n",
    "        self.data = os.listdir(self._input_path)  # List all image files in the directory\n",
    "        \n",
    "        self.transforms = transforms  # Transformations to be applied to the images\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)  # Return the number of data in the dataset\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        to_tensor = transforms.ToTensor()  # Transform the image to a tensor\n",
    "        \n",
    "        item = self.data[idx]  # Retrieve the data item by index\n",
    "        \n",
    "        input_ = Image.open(os.path.join(self._input_path, item))  # Open image\n",
    "        w, h = input_.size  # Get image dimensions\n",
    "        left = 0\n",
    "        top = 0\n",
    "        right = w\n",
    "        bottom = h / 2  # Take the top half of the image\n",
    "        input_ = input_.crop((left, top, right, bottom))  # Crop the image\n",
    "        \n",
    "        input_ = to_tensor(input_)  # Convert the cropped image to a tensor\n",
    "        \n",
    "        # Set seed for reproducibility\n",
    "        seed = np.random.randint(2147483647)\n",
    "        random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        if self.transforms is not None:\n",
    "            input_ = self.transforms(input_)  # Apply transformations if any\n",
    "        \n",
    "        img = input_.permute(1, 2, 0).numpy()  # Rearrange axes for color space conversion\n",
    "        img = sRGB_to_XYZ(img)  # Convert sRGB to XYZ\n",
    "        img = XYZ_to_Lab(img).transpose(2, 0, 1).astype(\"float32\")  # Convert XYZ to LAB\n",
    "        \n",
    "        L = torch.tensor(img[[0], ...] / 100)  # Normalize the L component\n",
    "        ab = torch.tensor(img[[1, 2], ...] / 256 + 0.5)  # Normalize the a and b components\n",
    "        \n",
    "        return L.to(device), ab.to(device)  # Return as tensor and send to the specified device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Colorization Dataset Class\n",
    "\n",
    "The `ImageColorizeDataset` class is a part of the PyTorch library that manages image datasets for colorization processes. The class loads and processes images in two modes: training and testing, depending on the argument provided during initialization.\n",
    "\n",
    "##### Initialization\n",
    "- **Path**: The location of the dataset directory containing the images.\n",
    "- **Device**: The device (`cpu` or `gpu`) where data will be processed.\n",
    "- **Train**: Indicates whether the dataset is for training or testing purposes.\n",
    "- **Transforms**: Transformations to be applied to images before processing.\n",
    "\n",
    "##### Loading Data\n",
    "- **`__len__`**: Returns the number of images in the dataset.\n",
    "- **`__getitem__`**: Retrieves an image by index, converts it into a tensor, applies transformations (if any), and converts the color space from sRGB to XYZ then to Lab.\n",
    "\n",
    "##### Transformation Process\n",
    "Transformations on images include resizing, normalizing, and converting color spaces. This process is crucial to prepare the data to meet the requirements of machine learning models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the dataset for testing with specified transformations and not in training mode\n",
    "test_data = ImageColorizeDataset(\"dataset\", \n",
    "\t\t\t\t\t\t\t\t transforms=t, train=False)\n",
    "# DataLoader for the test dataset, with a batch size of 8 and shuffling enabled\n",
    "test_dl = DataLoader(test_data, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the dataset for training with specified transformations and in training mode\n",
    "train_data = ImageColorizeDataset(\"dataset\", \n",
    "\t\t\t\t\t\t\t\t  transforms=t, train=True)\n",
    "# DataLoader for the training dataset, with a batch size of 8 and shuffling enabled\n",
    "train_dl = DataLoader(train_data, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Up Data Loaders\n",
    "\n",
    "This section of the code initializes and configures data loaders for both training and testing phases of an image colorization model using PyTorch.\n",
    "\n",
    "##### Test Data Loader\n",
    "- **Initialization**: The `ImageColorizeDataset` class is instantiated with the path `\"dataset1\"`, with the transformations defined by `t` and set to `train=False` to indicate that this dataset is for testing purposes.\n",
    "- **Data Loader**: The `DataLoader` is used to create an iterable over the test dataset. It is configured with a batch size of 8 and shuffling enabled to ensure that the model does not see the same sequence of images during testing, which helps simulate a more realistic testing environment.\n",
    "\n",
    "##### Training Data Loader\n",
    "- **Initialization**: Similarly, the `ImageColorizeDataset` is also instantiated for training, with the same path and transformations but with `train=True` to denote that this dataset will be used for training the model.\n",
    "- **Data Loader**: The `DataLoader` for training is similarly configured with a batch size of 8 and shuffling enabled. Shuffling the data during training is crucial as it prevents the model from learning the order of the dataset, thus improving the generalization capabilities of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the next batch of images and targets from the training DataLoader\n",
    "images, targets = next(iter(train_dl))\n",
    "\n",
    "# Convert LAB images back to RGB using the lab_to_rgb function for visualization\n",
    "to_show = lab_to_rgb(images, targets, device=device)\n",
    "\n",
    "# Create a grid of images combining the original and colorized images for display\n",
    "grid = torchvision.utils.make_grid(\n",
    "    torch.cat([images.expand(to_show.shape), to_show], dim=0),  # Concatenate original and colorized images\n",
    "    nrow=8,          # Number of images per row\n",
    "    # padding=4,       # Space between images\n",
    "    scale_each=True, # Scale images individually\n",
    "    # border=2         # Border size around images\n",
    ")\n",
    "\n",
    "# Plot the grid of images using matplotlib\n",
    "fig = plt.figure(figsize=(16,8))  # Set the figure size\n",
    "plt.imshow(grid.cpu().permute(1,2,0))  # Convert tensor to numpy array and display as image\n",
    "plt.axis('off')  # Hide axes\n",
    "plt.show()  # Display the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = grid.cpu().permute(1,2,0)\n",
    "plt.imshow((torch.split(a,130, dim=1)[1]))\n",
    "plt.axis('off')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = grid.cpu().permute(1,2,0)\n",
    "half_index = a.size(0) // 2\n",
    "second_portion = a[half_index:, :, :]\n",
    "plt.imshow((torch.split(second_portion,130, dim=1)[3]))\n",
    "plt.axis('off')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the Results of Image Colorization\n",
    "\n",
    "This section of the code demonstrates how to visualize the results of the image colorization model by combining the original (LAB) and RGB converted images.\n",
    "\n",
    "##### Step-by-Step Explanation:\n",
    "1. **Data Retrieval**: First, a batch of images and their corresponding color targets (LAB values) is retrieved from the training data loader using `next(iter(train_dl))`.\n",
    "\n",
    "2. **Color Space Conversion**: The `lab_to_rgb` function is called to convert these LAB images back into the RGB color space. This is essential for visual inspection, as RGB is the standard format for displaying images on most devices.\n",
    "\n",
    "3. **Image Grid Creation**:\n",
    "   - The original LAB images (converted for display) and the RGB images are concatenated to form a combined tensor.\n",
    "   - `torchvision.utils.make_grid` is utilized to arrange these images into a grid format, making it easier to compare the original and colorized versions side by side.\n",
    "\n",
    "4. **Visualization**:\n",
    "   - A figure of size 16x8 inches is created using `matplotlib`.\n",
    "   - The image grid is displayed using `plt.imshow`, with the axes turned off to emphasize the images themselves.\n",
    "   - The grid displays the original and RGB images in sequence, facilitating a direct visual comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generator <a class=\"anchor\" id=\"generator\"></a>\n",
    "\n",
    "UNet model was used as a generator. It takes image as an input. To randomize output of generator, dropout layers applied both at training and evalutaion time as a noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional Block with Residual Connection\n",
    "\n",
    "The `ConvBlock` class extends `nn.Module` and implements a convolutional block with a residual connection, typically used in modern deep learning architectures like ResNets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, norm_layer=nn.BatchNorm2d):\n",
    "        super().__init__()\n",
    "        # Defines a sequential container for two convolutional blocks with BatchNorm and ReLU activation\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride, bias=False),\n",
    "            norm_layer(out_channels),  # Normalization layer, here using BatchNorm\n",
    "            nn.ReLU(inplace=True),     # ReLU activation with in-place operation to save memory\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "            norm_layer(out_channels),  # Second normalization layer\n",
    "            nn.ReLU(inplace=True)      # Second ReLU activation\n",
    "        )\n",
    "        \n",
    "        # Identity mapping that may be used to match dimensions for the residual connection\n",
    "        self.identity = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)  # Final ReLU activation after adding the residual\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_ = x.detach().clone()  # Detach and clone the input to prevent modifications during forwarding\n",
    "        x_ = self.block(x_)       # Pass the input through the convolutional block\n",
    "        \n",
    "        residual = self.identity(x)  # Apply the identity mapping to the original input\n",
    "        \n",
    "        out = x_ + residual          # Add the output of the convolutional block to the identity mapping\n",
    "        \n",
    "        return self.relu(out)        # Apply a ReLU activation to the combined output and return it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder and Decoder Blocks in a Neural Network\n",
    "\n",
    "The `EncoderBlock` and `DecoderBlock` are fundamental components used in the architecture of autoencoders and U-Nets, typically used in tasks like image segmentation. \n",
    "The Encoder and Decoder blocks are crucial for building deep learning models that require precise spatial transformations, such as in image segmentation where detailed spatial resolution is necessary for accurate pixel-level predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, in_chans, out_chans, sampling_factor=2):\n",
    "        super().__init__()\n",
    "        # Sequential container for an encoder block that includes a max pooling followed by a convolutional block\n",
    "        self.block = nn.Sequential(\n",
    "            nn.MaxPool2d(sampling_factor),  # Reduces the spatial dimensions of the input\n",
    "            ConvBlock(in_chans, out_chans) # Applies a convolutional block to further process the data\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Forward pass of the encoder block: applies pooling and then convolution\n",
    "        return self.block(x)\n",
    "    \n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_chans, out_chans, sampling_factor=2):\n",
    "        super().__init__()\n",
    "        # Upsampling layer to increase the spatial dimensions of the input\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "        \n",
    "        # Convolutional block that processes the concatenated input from the upsampled feature map and the skip connection\n",
    "        self.block = ConvBlock(in_chans + out_chans, out_chans)\n",
    "        \n",
    "    def forward(self, x, skip):\n",
    "        # Upsamples the input feature map\n",
    "        x = self.upsample(x)\n",
    "        # Concatenates the upsampled feature map with the skip connection feature map\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        # Processes the concatenated feature maps using a convolutional block\n",
    "        x = self.block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### U-Net Architecture Implementation\n",
    "\n",
    "The `UNet` class implements a U-Net architecture, a popular model for biomedical image segmentation that features a symmetric encoder-decoder structure.\n",
    "The U-Net architecture effectively combines high-level feature extraction with precise localization, facilitated by skip connections that help in transferring spatial information to the decoder. This structure makes it particularly effective for tasks where precise segmentation is crucial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=2, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        # Initialize the encoder part of the U-Net with progressively increasing channels\n",
    "        self.encoder = nn.ModuleList([\n",
    "            ConvBlock(in_channels, 64),\n",
    "            EncoderBlock(64, 128),\n",
    "            EncoderBlock(128, 256),\n",
    "            EncoderBlock(256, 512),\n",
    "        ])\n",
    "        # Initialize the decoder part of the U-Net with progressively decreasing channels\n",
    "        self.decoder = nn.ModuleList([\n",
    "            DecoderBlock(512, 256),\n",
    "            DecoderBlock(256, 128),\n",
    "            DecoderBlock(128, 64)\n",
    "        ])\n",
    "        # Dropout layer to prevent overfitting\n",
    "        self.dropout = nn.Dropout2d(dropout_rate)\n",
    "        # Final convolution layer to map the decoded features to the desired number of output channels\n",
    "        self.logits = nn.Conv2d(in_channels=64, out_channels=out_channels, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = []\n",
    "        # Pass input through each encoder block, apply dropout, and store intermediate outputs for skip connections\n",
    "        for enc in self.encoder:\n",
    "            x = enc(x)\n",
    "            x = self.dropout(x)\n",
    "            encoded.append(x)\n",
    "\n",
    "        enc_out = encoded.pop()\n",
    "        \n",
    "        # Start the decoding process using the stored encoded features\n",
    "        for dec in self.decoder:\n",
    "            enc_out = encoded.pop()  # Retrieve the corresponding encoder output for skip connections\n",
    "            x = dec(x, enc_out)  # Decoder block processes input with skip connections\n",
    "        # Apply a sigmoid activation to the final layer's output to normalize the output to [0,1] range\n",
    "        return F.sigmoid(self.logits(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trigger the garbage collector to free memory from unreferenced objects.\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Discriminator <a class=\"anchor\" id=\"discriminator\"></a>\n",
    "\n",
    "Due to our input image shape `batch_size x 3 x 256 x 128`, in out PatchGAN discriminator we have 3 sequential `3 x 3` conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PatchGAN Network Architecture\n",
    "\n",
    "The `PatchGAN` class defines a convolutional neural network specifically designed for processing patches of images, commonly used in tasks such as image segmentation and texture synthesis. This model architecture is particularly effective in applications where local texture patterns are crucial, such as in style transfer and local image editing.\n",
    "PatchGAN can be used in various applications within computer vision, particularly in generative adversarial networks (GANs) where the model needs to discriminate between real and synthetic images at the scale of image patches, thus enabling detailed texture and pattern discrimination.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchGAN(nn.Module):\n",
    "    def __init__(self, in_channels, n_features=64, n_layers=3):\n",
    "        super().__init__()\n",
    "        # Initialize the PatchGAN architecture parameters\n",
    "        k_size = 4  # kernel size\n",
    "        p_size = 2  # padding size\n",
    "        \n",
    "        # Starting layer configuration with a convolutional layer and a LeakyReLU activation\n",
    "        seq = [\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=n_features, kernel_size=k_size, padding=p_size, stride=2),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]\n",
    "        \n",
    "        # Factor multipliers for feature map scaling in subsequent layers\n",
    "        f_mult = 1\n",
    "        f_mult_prev = 1\n",
    "        \n",
    "        # Construct additional convolutional layers as specified by n_layers\n",
    "        for i in range(1, n_layers):\n",
    "            f_mult_prev = f_mult\n",
    "            f_mult = min(2 ** i, 8)  # Update feature multiplier with constraints\n",
    "            \n",
    "            seq.append(nn.Conv2d(in_channels=f_mult_prev * n_features, out_channels=f_mult * n_features, kernel_size=k_size, padding=p_size, stride=2))\n",
    "            seq.append(nn.BatchNorm2d(f_mult * n_features))  # Batch normalization for stability\n",
    "            seq.append(nn.LeakyReLU(0.2, True))  # LeakyReLU for non-linear processing\n",
    "\n",
    "        # Last convolutional layers before the final output layer\n",
    "        f_mult_prev = f_mult\n",
    "        f_mult = min(2 ** n_layers, 8)\n",
    "        \n",
    "        seq += [\n",
    "            nn.Conv2d(n_features * f_mult_prev, n_features * f_mult, kernel_size=k_size, stride=1, padding=p_size),\n",
    "            nn.BatchNorm2d(n_features * f_mult),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]\n",
    "\n",
    "        # Final convolutional layer to produce a 1-channel prediction map\n",
    "        seq += [nn.Conv2d(n_features * f_mult, 1, kernel_size=k_size, stride=1, padding=p_size)]\n",
    "        self.model = nn.Sequential(*seq)\n",
    "\n",
    "    def forward(self, x, label):\n",
    "        # Concatenate input and label along the channel dimension for conditional GAN processing\n",
    "        x = torch.cat((x, label), dim=1)\n",
    "        x = self.model(x)  # Pass through the network\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 64, 129, 65]           3,136\n",
      "         LeakyReLU-2          [-1, 64, 129, 65]               0\n",
      "            Conv2d-3          [-1, 128, 65, 33]         131,200\n",
      "       BatchNorm2d-4          [-1, 128, 65, 33]             256\n",
      "         LeakyReLU-5          [-1, 128, 65, 33]               0\n",
      "            Conv2d-6          [-1, 256, 33, 17]         524,544\n",
      "       BatchNorm2d-7          [-1, 256, 33, 17]             512\n",
      "         LeakyReLU-8          [-1, 256, 33, 17]               0\n",
      "            Conv2d-9          [-1, 512, 34, 18]       2,097,664\n",
      "      BatchNorm2d-10          [-1, 512, 34, 18]           1,024\n",
      "        LeakyReLU-11          [-1, 512, 34, 18]               0\n",
      "           Conv2d-12            [-1, 1, 35, 19]           8,193\n",
      "================================================================\n",
      "Total params: 2,766,529\n",
      "Trainable params: 2,766,529\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 8192.00\n",
      "Forward/backward pass size (MB): 24.94\n",
      "Params size (MB): 10.55\n",
      "Estimated Total Size (MB): 8227.49\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\.conda\\envs\\ulos\\lib\\site-packages\\torchsummary\\torchsummary.py:100: RuntimeWarning: overflow encountered in scalar multiply\n",
      "  total_input_size = abs(np.prod(input_size) * batch_size * 4. / (1024 ** 2.))\n"
     ]
    }
   ],
   "source": [
    "D = PatchGAN(in_channels=3).to(device)  # Initialize the PatchGAN discriminator\n",
    "\n",
    "# Display the model architecture\n",
    "summary(D, [(1, image_size[0], image_size[1]), (2, image_size[0], image_size[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PatchGAN Model\n",
    "\n",
    "The `PatchGAN` model is initialized with three input channels and configured to process images such as those in RGB format. The model is then moved to a computational device (CPU or GPU) for efficient processing. Here is an explanation of each step:\n",
    "\n",
    "##### Model Initialization and Device Allocation:\n",
    "- **PatchGAN(in_channels=3)**: Constructs a `PatchGAN` model that accepts images with three channels (RGB). This model is particularly used in applications like image synthesis or segmentation where understanding local patches is crucial.\n",
    "- **.to(device)**: This method transfers the model to a specified device (`cpu` or `gpu`). This is essential for leveraging hardware acceleration during training or inference, enhancing performance and efficiency.\n",
    "\n",
    "##### Model Summary with torchsummary:\n",
    "- **summary(D, [(1, image_size[0], image_size[1]), (2, image_size[0], image_size[1])])**: Provides a detailed summary of the model. The summary includes layer-by-layer details, output shapes, and the number of parameters at each stage.\n",
    "  - The parameters for the `summary` function indicate the size of the input tensors:\n",
    "    - The first input tensor, with 1 channel and dimensions defined by `image_size`, could represent a specific feature map or modality.\n",
    "    - The second input tensor, with 2 channels and the same spatial dimensions, might carry additional contextual or conditional information influencing the network's predictions.\n",
    "\n",
    "#### Practical Application:\n",
    "This initialization and summary are particularly valuable for developers and researchers:\n",
    "- **Model Development**: Understanding the internal architecture, including the flow and transformation of data through the network, is crucial during the development and debugging phases.\n",
    "- **Resource Management**: Insight into parameter count and memory usage helps in optimizing the model for different computational environments, ensuring efficient deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 128]             576\n",
      "       BatchNorm2d-2         [-1, 64, 256, 128]             128\n",
      "              ReLU-3         [-1, 64, 256, 128]               0\n",
      "            Conv2d-4         [-1, 64, 256, 128]          36,864\n",
      "       BatchNorm2d-5         [-1, 64, 256, 128]             128\n",
      "              ReLU-6         [-1, 64, 256, 128]               0\n",
      "            Conv2d-7         [-1, 64, 256, 128]             576\n",
      "              ReLU-8         [-1, 64, 256, 128]               0\n",
      "         ConvBlock-9         [-1, 64, 256, 128]               0\n",
      "        Dropout2d-10         [-1, 64, 256, 128]               0\n",
      "        MaxPool2d-11          [-1, 64, 128, 64]               0\n",
      "           Conv2d-12         [-1, 128, 128, 64]          73,728\n",
      "      BatchNorm2d-13         [-1, 128, 128, 64]             256\n",
      "             ReLU-14         [-1, 128, 128, 64]               0\n",
      "           Conv2d-15         [-1, 128, 128, 64]         147,456\n",
      "      BatchNorm2d-16         [-1, 128, 128, 64]             256\n",
      "             ReLU-17         [-1, 128, 128, 64]               0\n",
      "           Conv2d-18         [-1, 128, 128, 64]          73,728\n",
      "             ReLU-19         [-1, 128, 128, 64]               0\n",
      "        ConvBlock-20         [-1, 128, 128, 64]               0\n",
      "     EncoderBlock-21         [-1, 128, 128, 64]               0\n",
      "        Dropout2d-22         [-1, 128, 128, 64]               0\n",
      "        MaxPool2d-23          [-1, 128, 64, 32]               0\n",
      "           Conv2d-24          [-1, 256, 64, 32]         294,912\n",
      "      BatchNorm2d-25          [-1, 256, 64, 32]             512\n",
      "             ReLU-26          [-1, 256, 64, 32]               0\n",
      "           Conv2d-27          [-1, 256, 64, 32]         589,824\n",
      "      BatchNorm2d-28          [-1, 256, 64, 32]             512\n",
      "             ReLU-29          [-1, 256, 64, 32]               0\n",
      "           Conv2d-30          [-1, 256, 64, 32]         294,912\n",
      "             ReLU-31          [-1, 256, 64, 32]               0\n",
      "        ConvBlock-32          [-1, 256, 64, 32]               0\n",
      "     EncoderBlock-33          [-1, 256, 64, 32]               0\n",
      "        Dropout2d-34          [-1, 256, 64, 32]               0\n",
      "        MaxPool2d-35          [-1, 256, 32, 16]               0\n",
      "           Conv2d-36          [-1, 512, 32, 16]       1,179,648\n",
      "      BatchNorm2d-37          [-1, 512, 32, 16]           1,024\n",
      "             ReLU-38          [-1, 512, 32, 16]               0\n",
      "           Conv2d-39          [-1, 512, 32, 16]       2,359,296\n",
      "      BatchNorm2d-40          [-1, 512, 32, 16]           1,024\n",
      "             ReLU-41          [-1, 512, 32, 16]               0\n",
      "           Conv2d-42          [-1, 512, 32, 16]       1,179,648\n",
      "             ReLU-43          [-1, 512, 32, 16]               0\n",
      "        ConvBlock-44          [-1, 512, 32, 16]               0\n",
      "     EncoderBlock-45          [-1, 512, 32, 16]               0\n",
      "        Dropout2d-46          [-1, 512, 32, 16]               0\n",
      "         Upsample-47          [-1, 512, 64, 32]               0\n",
      "           Conv2d-48          [-1, 256, 64, 32]       1,769,472\n",
      "      BatchNorm2d-49          [-1, 256, 64, 32]             512\n",
      "             ReLU-50          [-1, 256, 64, 32]               0\n",
      "           Conv2d-51          [-1, 256, 64, 32]         589,824\n",
      "      BatchNorm2d-52          [-1, 256, 64, 32]             512\n",
      "             ReLU-53          [-1, 256, 64, 32]               0\n",
      "           Conv2d-54          [-1, 256, 64, 32]       1,769,472\n",
      "             ReLU-55          [-1, 256, 64, 32]               0\n",
      "        ConvBlock-56          [-1, 256, 64, 32]               0\n",
      "     DecoderBlock-57          [-1, 256, 64, 32]               0\n",
      "         Upsample-58         [-1, 256, 128, 64]               0\n",
      "           Conv2d-59         [-1, 128, 128, 64]         442,368\n",
      "      BatchNorm2d-60         [-1, 128, 128, 64]             256\n",
      "             ReLU-61         [-1, 128, 128, 64]               0\n",
      "           Conv2d-62         [-1, 128, 128, 64]         147,456\n",
      "      BatchNorm2d-63         [-1, 128, 128, 64]             256\n",
      "             ReLU-64         [-1, 128, 128, 64]               0\n",
      "           Conv2d-65         [-1, 128, 128, 64]         442,368\n",
      "             ReLU-66         [-1, 128, 128, 64]               0\n",
      "        ConvBlock-67         [-1, 128, 128, 64]               0\n",
      "     DecoderBlock-68         [-1, 128, 128, 64]               0\n",
      "         Upsample-69        [-1, 128, 256, 128]               0\n",
      "           Conv2d-70         [-1, 64, 256, 128]         110,592\n",
      "      BatchNorm2d-71         [-1, 64, 256, 128]             128\n",
      "             ReLU-72         [-1, 64, 256, 128]               0\n",
      "           Conv2d-73         [-1, 64, 256, 128]          36,864\n",
      "      BatchNorm2d-74         [-1, 64, 256, 128]             128\n",
      "             ReLU-75         [-1, 64, 256, 128]               0\n",
      "           Conv2d-76         [-1, 64, 256, 128]         110,592\n",
      "             ReLU-77         [-1, 64, 256, 128]               0\n",
      "        ConvBlock-78         [-1, 64, 256, 128]               0\n",
      "     DecoderBlock-79         [-1, 64, 256, 128]               0\n",
      "           Conv2d-80          [-1, 2, 256, 128]             130\n",
      "================================================================\n",
      "Total params: 11,655,938\n",
      "Trainable params: 11,655,938\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.12\n",
      "Forward/backward pass size (MB): 657.50\n",
      "Params size (MB): 44.46\n",
      "Estimated Total Size (MB): 702.09\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "G = UNet(in_channels=1, out_channels=2).to(device)\n",
    "# G2 = UNet(in_channels=2, out_channels=1).to(device)\n",
    "\n",
    "# summary(G, (1, 384, 384))\n",
    "summary(G, (1, image_size[0], image_size[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Trainer <a class=\"anchor\" id=\"training\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer: \n",
    "    def __init__(self, G, D, device, batch_size=32, lr_g=1e-4, lr_d=4e-4, l1_lambda=125, d2g_ratio=2, plot_rate=1):\n",
    "        self.G = G\n",
    "        self.D = D\n",
    "        \n",
    "        self.L1_G_loss = nn.L1Loss()\n",
    "        self.G_loss = nn.BCEWithLogitsLoss()\n",
    "        self.D_loss = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "        self.G_optim = torch.optim.AdamW(params=G.parameters(), lr=lr_g)\n",
    "        self.D_optim = torch.optim.AdamW(params=D.parameters(), lr=lr_d)\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.l1_lambda = l1_lambda\n",
    "        \n",
    "        self.loss_G_per_epoch = []\n",
    "        self.loss_D_per_epoch = []\n",
    "        self.loss_D_real_per_epoch = []\n",
    "        self.loss_D_fake_per_epoch = []\n",
    "        \n",
    "        self.loss_G_history = []\n",
    "        self.loss_D_history = []\n",
    "        self.loss_D_real_history = []\n",
    "        self.loss_D_fake_history = []\n",
    "\n",
    "        self.ssim_history = []\n",
    "        self.colourfulness_history = []\n",
    "        \n",
    "        self.d2g_ratio = d2g_ratio\n",
    "        self.device = device\n",
    "        \n",
    "        self.plot_rate = plot_rate\n",
    "    \n",
    "    def train(self, dataloader, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            self.loss_G_history.append([])\n",
    "            self.loss_D_history.append([])\n",
    "            self.loss_D_real_history.append([])\n",
    "            self.loss_D_fake_history.append([])\n",
    "            \n",
    "            print(f'EPOCH: {epoch + 1}')\n",
    "            for i, (images, targets) in enumerate(tqdm(dataloader)):\n",
    "                \n",
    "                self._train_discriminator(images, targets)\n",
    "                \n",
    "                if (i + 1) % self.d2g_ratio == 0:\n",
    "                    self._train_generator(images, targets)\n",
    "    \n",
    "            self.loss_G_per_epoch.append(np.mean(self.loss_G_history[-1]))\n",
    "            self.loss_D_per_epoch.append(np.mean(self.loss_D_history[-1]))\n",
    "            self.loss_D_real_per_epoch.append(np.mean(self.loss_D_real_history[-1]))\n",
    "            self.loss_D_fake_per_epoch.append(np.mean(self.loss_D_fake_history[-1]))\n",
    "            \n",
    "            if (epoch + 1) % self.plot_rate == 0:\n",
    "                self._plot_epoch_stats(epoch)\n",
    "                self._plot_fake_images(images, targets)\n",
    "            self._plot_stats()\n",
    "\n",
    "    def _train_generator(self, inputs, targets):\n",
    "        self.G_optim.zero_grad()\n",
    "        \n",
    "        self.G.train()\n",
    "        self.D.eval()\n",
    "        \n",
    "        fake_targets = self.G(inputs)\n",
    "        \n",
    "        predictions = self.D(inputs, fake_targets)\n",
    "        fake_labels = torch.ones(*predictions.shape, device=self.device)  # Real label for generator\n",
    "        \n",
    "        L1_loss = self.L1_G_loss(fake_targets, targets)\n",
    "        BCE_loss = self.G_loss(predictions, fake_labels)\n",
    "        loss_g = BCE_loss + self.l1_lambda * L1_loss\n",
    "        self.loss_G_history[-1].append(loss_g.item())\n",
    "        loss_g.backward()\n",
    "        self.G_optim.step()\n",
    "                \n",
    "    def _train_discriminator(self, inputs, real_targets):\n",
    "        self.D_optim.zero_grad()\n",
    "        \n",
    "        self.G.eval()\n",
    "        self.D.train()\n",
    "        \n",
    "        real_predictions = self.D(inputs, real_targets)\n",
    "        real_labels = torch.ones(*real_predictions.shape, device=self.device)\n",
    "\n",
    "        real_loss = self.D_loss(real_predictions, real_labels)\n",
    "        \n",
    "        fake_targets = self.G(inputs)\n",
    "        fake_predictions = self.D(inputs, fake_targets.detach())\n",
    "        fake_labels = torch.zeros(*fake_predictions.shape, device=self.device)\n",
    "\n",
    "        fake_loss = self.D_loss(fake_predictions, fake_labels)\n",
    "        \n",
    "        loss_d = (real_loss + fake_loss) / 2\n",
    "        \n",
    "        self.loss_D_history[-1].append(loss_d.item())\n",
    "        self.loss_D_real_history[-1].append(real_loss.item())\n",
    "        self.loss_D_fake_history[-1].append(fake_loss.item())\n",
    "\n",
    "        loss_d.backward()\n",
    "        self.D_optim.step()\n",
    "        \n",
    "    def _plot_fake_images(self, images, targets, nrow=8):\n",
    "        \"\"\"\n",
    "        Showing the generator's results\n",
    "        \"\"\"\n",
    "        \n",
    "        self.G.eval()\n",
    "                \n",
    "        fake = self.G(images)\n",
    "        \n",
    "        to_show = lab_to_rgb_save(images, fake, device=self.device)\n",
    "        to_show_real = lab_to_rgb(images, targets, device=self.device)\n",
    "\n",
    "        save_dir=\"./output\"\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "        # Save images to disk\n",
    "        for idx, img in enumerate(to_show):\n",
    "            plt.imsave(os.path.join(save_dir, f\"image_{idx}.png\"), img.clip(0, 1))\n",
    "\n",
    "        # Calculate SSIM\n",
    "        score_ssim = calculate_ssim(images, fake, targets)\n",
    "        print(f\"SSIM: {score_ssim}\")\n",
    "\n",
    "        # Calculate Colourfulness\n",
    "        score_colourfulness = calculate_colourfulness(images, fake)\n",
    "        print(f\"Colourfulness: {score_colourfulness}\")\n",
    "\n",
    "        a = fake[:, 0, :, :].unsqueeze(1).expand(to_show.shape)\n",
    "        b = fake[:, 1, :, :].unsqueeze(1).expand(to_show.shape)\n",
    "        grid = torchvision.utils.make_grid(torch.cat([images.expand(to_show.shape), a, b, to_show, to_show_real], dim=0), nrow=8, padding=1, scale_each=True)\n",
    "\n",
    "        fig = plt.figure(figsize=(16,8))\n",
    "        plt.imshow((grid.cpu().permute(1,2,0).numpy() * 255).astype(np.uint8))\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "    def _plot_stats(self):\n",
    "        \"\"\"\n",
    "        Plotting stats of history training\n",
    "        \"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(10, 4))\n",
    "        sns.lineplot(self.loss_D_per_epoch, label=\"discriminator\", ax=axes[0][0])\n",
    "        sns.lineplot(self.loss_G_per_epoch, label=\"generator\", ax=axes[0][1])\n",
    "        \n",
    "        sns.lineplot(self.loss_D_real_per_epoch, label=\"real\", ax=axes[1][0])\n",
    "        sns.lineplot(self.loss_D_fake_per_epoch, label=\"fake\", ax=axes[1][1])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "    def _plot_epoch_stats(self, epoch):\n",
    "        \"\"\"\n",
    "        Plotting stats of history training\n",
    "        \"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(10, 4))\n",
    "        sns.lineplot(self.loss_D_history[epoch], label=\"discriminator\", ax=axes[0][0])\n",
    "        sns.lineplot(self.loss_G_history[epoch], label=\"generator\", ax=axes[0][1])\n",
    "        \n",
    "        sns.lineplot(self.loss_D_real_history[epoch], label=\"real\", ax=axes[1][0])\n",
    "        sns.lineplot(self.loss_D_fake_history[epoch], label=\"fake\", ax=axes[1][1])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def _plot_losses(self):\n",
    "        \"\"\"\n",
    "        Plot the generator and discriminator losses per epoch.\n",
    "        \"\"\"\n",
    "        epochs = range(1, len(self.loss_G_per_epoch) + 1)\n",
    "\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(epochs, self.loss_G_per_epoch, label='Generator loss', color='blue')\n",
    "        plt.plot(epochs, self.loss_D_per_epoch, label='Discriminator loss', color='red')\n",
    "        plt.title('Loss vs. Epoch')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_ssim_and_colourfulness(self):\n",
    "        \"\"\"\n",
    "        Plot SSIM and Colourfulness over epochs.\n",
    "        \"\"\"\n",
    "        epochs = range(1, len(self.ssim_history) + 1)\n",
    "\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(epochs, self.ssim_history, label='SSIM', color='green')\n",
    "        plt.plot(epochs, self.colourfulness_history, label='Colourfulness', color='purple')\n",
    "        plt.title('SSIM and Colourfulness vs. Epoch')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Score')\n",
    "        plt.legend()\n",
    "        plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trainer Class for GANs\n",
    "\n",
    "##### Key Components and Initialization\n",
    "- **Models and Device**: The trainer initializes with generator (`G`) and discriminator (`D`) models, and specifies the device (`CPU` or `GPU`) for computation.\n",
    "- **Loss Functions**: Utilizes L1 and Binary Cross-Entropy (BCE) losses to measure accuracy and fidelity in generated images.\n",
    "- **Optimizers**: Adam optimizers are employed for both models to iteratively improve through gradient descent.\n",
    "\n",
    "##### Training Process\n",
    "- **Batch and Epoch Management**: Handles data loading and batches through the provided `dataloader`. The training is epoch-based, with detailed loss tracking and periodic updates.\n",
    "- **Discriminator and Generator Training**: Trains the discriminator more frequently than the generator based on a specified rate (`discriminator_to_generator_training_rate`), balancing the training between sharpening discriminator accuracy and enhancing generator quality.\n",
    "- **Loss Tracking and Visualization**: Maintains a comprehensive log of losses for both real and fake inputs to monitor the training progress. Visualizations of losses and generated images are periodically produced to assess the model's performance and convergence.\n",
    "\n",
    "##### Methods for Detailed Operations\n",
    "- **_train_generator() and _train_discriminator()**: Core methods that handle the training of the generator and discriminator, including backpropagation and parameter updates.\n",
    "- **_plot_fake_images() and _plot_stats()**: Utility methods for visual output and statistical analysis, providing insights into the training process and outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ssim(L, ab_gen, ab_gt):\n",
    "    \"\"\"\n",
    "    Calculate the Structural Similarity Index (SSIM)\n",
    "    \"\"\"\n",
    "    L = 100 * L # Scale the L component from 0-1 to 0-100\n",
    "    ab_gen = (ab_gen - 0.5) * 256 # Adjust the a and b components to the correct range\n",
    "    ab_gt = (ab_gt - 0.5) * 256 # Adjust the a and b components to the correct range\n",
    "\n",
    "    Lab_gens = torch.cat([L, ab_gen], dim=1).permute(0, 2, 3, 1).detach().cpu().numpy() # Combine L, a, b, and rearrange the format for processing\n",
    "    Lab_gts = torch.cat([L, ab_gt], dim=1).permute(0, 2, 3, 1).detach().cpu().numpy()   # Combine L, a, b, and rearrange the format for processing\n",
    "    \n",
    "    scores = [] # Initialize a list to store the SSIM scores\n",
    "    for img_gen, img_gt in zip(Lab_gens, Lab_gts):  # Iterate over the generated and ground truth images\n",
    "        img_gen = Lab_to_XYZ(img_gen)   # Convert LAB to XYZ\n",
    "        img_gen = XYZ_to_sRGB(img_gen)  # Convert XYZ to sRGB\n",
    "        \n",
    "        img_gt = Lab_to_XYZ(img_gt)    # Convert LAB to XYZ\n",
    "        img_gt = XYZ_to_sRGB(img_gt)    # Convert XYZ to sRGB\n",
    "        \n",
    "        scores.append(ssim(img_gen, img_gt, channel_axis=-1, data_range=255)) # Calculate the SSIM score\n",
    "\n",
    "    return round(np.mean(scores), 4)    # Return the mean SSIM score\n",
    "\n",
    "def calculate_colourfulness(L, ab_gen): \n",
    "    \"\"\"\n",
    "    Calculate the Colourfulness.\n",
    "    References\n",
    "    ----------\n",
    "    D. Hasler and S.E.Suesstrunk, ``Measuring colorfulness in natural images,\" Human\n",
    "    Vision andElectronicImagingVIII, Proceedings of the SPIE, 5007:87-95, 2003.\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    L = 100 * L     # Scale the L component from 0-1 to 0-100\n",
    "    ab_gen = (ab_gen - 0.5) * 256   # Adjust the a and b components to the correct range\n",
    "\n",
    "    Lab_gens = torch.cat([L, ab_gen], dim=1).permute(0, 2, 3, 1).detach().cpu().numpy()     # Combine L, a, b, and rearrange the format for processing\n",
    "    \n",
    "    scores = []     # Initialize a list to store the colourfulness scores\n",
    "    for img_gen in Lab_gens:   # Iterate over the generated images\n",
    "        img_gen = Lab_to_XYZ(img_gen)  # Convert LAB to XYZ\n",
    "        img_gen = XYZ_to_sRGB(img_gen)  # Convert XYZ to sRGB\n",
    "        \n",
    "        rg = img_gen[:, 0] - img_gen[:, 1] # Calculate the red-green channel\n",
    "        yb = 0.5 * (img_gen[:, 0] + img_gen[:, 1]) - img_gen[:, 2] # Calculate the yellow-blue channel\n",
    "\n",
    "        mean_rgyb = np.sqrt(np.mean(rg) ** 2 + np.mean(yb) ** 2) # Calculate the mean of the RG and YB channels\n",
    "        std_rgyb = np.sqrt(np.std(rg) ** 2 + np.std(yb) ** 2)   # Calculate the standard deviation of the RG and YB channels\n",
    "\n",
    "        scores.append(std_rgyb + 0.3 * mean_rgyb) # Calculate the colourfulness score\n",
    "    \n",
    "    return round(np.mean(scores), 4)    # Return the mean colourfulness score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measuring Image Quality in Image Generation Tasks\n",
    "\n",
    "In tasks involving image generation, such as those with Generative Adversarial Networks (GANs), it's crucial to quantitatively assess the quality of generated images. Two important metrics are used for this purpose: the Structural Similarity Index (SSIM) and the Colourfulness metric.\n",
    "\n",
    "##### Structural Similarity Index (SSIM)\n",
    "\n",
    "SSIM is a perception-based model that quantifies the similarity between two images. It is used to measure the quality of reconstruction or generation in comparison to an original or ground-truth image.\n",
    "\n",
    "- **Usage**: `calculate_ssim(L, ab_gen, ab_gt)`\n",
    "- **Input**:\n",
    "  - `L`: Lightness component of the LAB color space.\n",
    "  - `ab_gen`: Generated image color components.\n",
    "  - `ab_gt`: Ground truth image color components.\n",
    "- **Process**:\n",
    "  - The function normalizes the L and AB components to standard LAB color space ranges.\n",
    "  - Converts LAB color space images to sRGB for proper visualization.\n",
    "  - Calculates SSIM for each image in the batch and averages the scores.\n",
    "\n",
    "##### Colourfulness Metric\n",
    "\n",
    "Based on a study by Hasler and Suesstrunk, the Colourfulness metric measures the vividness of an image, which can be particularly useful in evaluating the performance of color generation models.\n",
    "\n",
    "- **Usage**: `calculate_colourfulness(L, ab_gen)`\n",
    "- **Input**:\n",
    "  - `L`: Lightness component of the LAB color space.\n",
    "  - `ab_gen`: Generated image color components.\n",
    "- **Process**:\n",
    "  - Normalizes and converts the LAB images to sRGB.\n",
    "  - Computes differences between the red-green and yellow-blue components.\n",
    "  - Calculates mean and standard deviation of these differences to derive the colourfulness score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(G, D, device) # Initialize the trainer with the generator and discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3090d98887554d7e923821cb91c06bb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Third dimension must be 3 or 4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the models for 50 epochs\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 56\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, dataloader, epochs)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplot_rate \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_plot_epoch_stats(epoch)\n\u001b[1;32m---> 56\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_fake_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_plot_stats()\n",
      "Cell \u001b[1;32mIn[19], line 120\u001b[0m, in \u001b[0;36mTrainer._plot_fake_images\u001b[1;34m(self, images, targets, nrow)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# Save images to disk\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, img \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(to_show):\n\u001b[1;32m--> 120\u001b[0m     \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimsave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43midx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# Calculate SSIM\u001b[39;00m\n\u001b[0;32m    123\u001b[0m score_ssim \u001b[38;5;241m=\u001b[39m calculate_ssim(images, fake, targets)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\.conda\\envs\\ulos\\lib\\site-packages\\matplotlib\\pyplot.py:2396\u001b[0m, in \u001b[0;36mimsave\u001b[1;34m(fname, arr, **kwargs)\u001b[0m\n\u001b[0;32m   2392\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(matplotlib\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimsave)\n\u001b[0;32m   2393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimsave\u001b[39m(\n\u001b[0;32m   2394\u001b[0m     fname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m os\u001b[38;5;241m.\u001b[39mPathLike \u001b[38;5;241m|\u001b[39m BinaryIO, arr: ArrayLike, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   2395\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2396\u001b[0m     matplotlib\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimsave(fname, arr, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\.conda\\envs\\ulos\\lib\\site-packages\\matplotlib\\image.py:1617\u001b[0m, in \u001b[0;36mimsave\u001b[1;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[0;32m   1615\u001b[0m     sm \u001b[38;5;241m=\u001b[39m cm\u001b[38;5;241m.\u001b[39mScalarMappable(cmap\u001b[38;5;241m=\u001b[39mcmap)\n\u001b[0;32m   1616\u001b[0m     sm\u001b[38;5;241m.\u001b[39mset_clim(vmin, vmax)\n\u001b[1;32m-> 1617\u001b[0m     rgba \u001b[38;5;241m=\u001b[39m \u001b[43msm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_rgba\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pil_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1619\u001b[0m     pil_kwargs \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\.conda\\envs\\ulos\\lib\\site-packages\\matplotlib\\cm.py:483\u001b[0m, in \u001b[0;36mScalarMappable.to_rgba\u001b[1;34m(self, x, alpha, bytes, norm)\u001b[0m\n\u001b[0;32m    481\u001b[0m     xx \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 483\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThird dimension must be 3 or 4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xx\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    485\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m norm \u001b[38;5;129;01mand\u001b[39;00m (xx\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m xx\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "\u001b[1;31mValueError\u001b[0m: Third dimension must be 3 or 4"
     ]
    }
   ],
   "source": [
    "# Train the models for 50 epochs\n",
    "trainer.train(train_dl, epochs=1) \t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot_ssim_and_colourfulness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer._plot_losses() \t# Plot the generator and discriminator losses per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.G\t# Set the generator to evaluation mode"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elraang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
