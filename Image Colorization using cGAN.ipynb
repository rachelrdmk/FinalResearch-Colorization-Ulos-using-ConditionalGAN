{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGE COLORIZATION USING cGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Contents**\n",
    "\n",
    "1. [Import Packages](#packages)\n",
    "2. [Utils](#utils)\n",
    "3. [Data preparation](#dataset)\n",
    "4. [Generator architecture](#generator)\n",
    "5. [Discriminator architecture](#discriminator)\n",
    "6. [Trainer](#training)\n",
    "7. [Validation](#validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages <a class=\"anchor\" id=\"packages\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "from colour import sRGB_to_XYZ, XYZ_to_Lab, Lab_to_XYZ, XYZ_to_sRGB\n",
    "\n",
    "import gc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils <a class=\"anchor\" id=\"utils\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lab_to_rgb(L, ab, device):\n",
    "    \"\"\"\n",
    "    Takes a batch of images\n",
    "    \"\"\"\n",
    "    L = 100 * L\n",
    "    ab = (ab - 0.5) * 256\n",
    "    Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).detach().cpu().numpy()\n",
    "    rgb_imgs = []\n",
    "    for img in Lab:\n",
    "        img = Lab_to_XYZ(img)\n",
    "        img = XYZ_to_sRGB(img)\n",
    "        rgb_imgs.append(img)\n",
    "    return torch.tensor(np.stack(rgb_imgs, axis=0)).permute(0, 3, 1, 2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_size = (384, 384)\n",
    "image_size = (256, 128)\n",
    "\n",
    "t = transforms.Compose([\n",
    "    transforms.Resize(image_size, antialias=True),\n",
    "    transforms.Normalize(mean=0, std=0.5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageColorizeDataset(Dataset):\n",
    "    def __init__(self, path: str, device='cpu', train: bool = False, transforms = None ):\n",
    "        _mode = 'train' if train else 'test'\n",
    "        \n",
    "        self.device = device\n",
    "        self._input_path = os.path.join(path, f'{_mode}_color')\n",
    "        \n",
    "        self.data = os.listdir(self._input_path)\n",
    "        \n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        to_tensor = transforms.ToTensor()\n",
    "        \n",
    "        item = self.data[idx]\n",
    "        \n",
    "        input_ = Image.open(os.path.join(self._input_path, item))\n",
    "        w, h = input_.size\n",
    "        left = 0\n",
    "        top = 0\n",
    "        right = w\n",
    "        bottom = h / 2\n",
    "        input_ = input_.crop((left, top, right, bottom))\n",
    "        \n",
    "        input_ = to_tensor(input_)\n",
    "        \n",
    "        seed = np.random.randint(2147483647)\n",
    "        random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        if self.transforms is not None:\n",
    "            input_ = self.transforms(input_)\n",
    "        \n",
    "        img = input_.permute(1, 2, 0).numpy()\n",
    "        img = sRGB_to_XYZ(img)\n",
    "        img = XYZ_to_Lab(img).transpose(2, 0, 1).astype(\"float32\")\n",
    "        \n",
    "        L = torch.tensor(img[[0], ...] / 100) \n",
    "        ab = torch.tensor(img[[1, 2], ...] / 256 + 0.5)\n",
    "        \n",
    "        return L.to(device), ab.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = ImageColorizeDataset(\"data\", transforms=t, train=False)\n",
    "test_dl = DataLoader(test_data, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ImageColorizeDataset(\"data\",\n",
    "                                  transforms=t, train=True)\n",
    "train_dl = DataLoader(train_data, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets = next(iter(train_dl))\n",
    "\n",
    "to_show = lab_to_rgb(images, targets, device=device)\n",
    "\n",
    "grid = torchvision.utils.make_grid(torch.cat([images.expand(to_show.shape), to_show], dim=0),\n",
    "                                   nrow=8, padding=0, scale_each=True)\n",
    "\n",
    "fig = plt.figure(figsize=(16,8))\n",
    "plt.imshow(grid.cpu().permute(1,2,0))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator <a class=\"anchor\" id=\"generator\"></a>\n",
    "\n",
    "UNet model was used as a generator. It takes image as an input. To randomize output of generator, dropout layers applied both at training and evalutaion time as a noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, norm_layer = nn.BatchNorm2d):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.identity = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "    \n",
    "        x_ = x.detach().clone()\n",
    "        \n",
    "        x_ = self.block(x_)\n",
    "        \n",
    "        residual = self.identity(x)\n",
    "        \n",
    "        out = x_ + residual\n",
    "        \n",
    "        return self.relu(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, in_chans, out_chans, sampling_factor=2):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.MaxPool2d(sampling_factor),\n",
    "            ConvBlock(in_chans, out_chans)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "    \n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_chans, out_chans, sampling_factor=2):\n",
    "        super().__init__()\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "        \n",
    "        self.block = ConvBlock(in_chans + out_chans, out_chans)\n",
    "        \n",
    "    def forward(self, x, skip):\n",
    "        x  = self.upsample(x)\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        x = self.block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=2, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.encoder = nn.ModuleList([\n",
    "            ConvBlock(in_channels, 64),\n",
    "            EncoderBlock(64, 128),\n",
    "            EncoderBlock(128, 256),\n",
    "            EncoderBlock(256, 512),\n",
    "\n",
    "        ])\n",
    "        self.decoder = nn.ModuleList([\n",
    "            DecoderBlock(512, 256),\n",
    "            DecoderBlock(256, 128),\n",
    "            DecoderBlock(128, 64)\n",
    "        ])\n",
    "        \n",
    "        self.dropout = nn.Dropout2d(dropout_rate)\n",
    "        \n",
    "        self.logits = nn.Conv2d(in_channels=64, out_channels=out_channels, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        \n",
    "        encoded = []\n",
    "        for enc in self.encoder:\n",
    "            x = enc(x)\n",
    "            x = self.dropout(x)\n",
    "            encoded.append(x)\n",
    "    \n",
    "        enc_out = encoded.pop()\n",
    "\n",
    "        for dec in self.decoder:\n",
    "            enc_out = encoded.pop()\n",
    "            x = dec(x, enc_out)\n",
    "        return F.sigmoid(self.logits(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator <a class=\"anchor\" id=\"discriminator\"></a>\n",
    "\n",
    "Due to our input image shape `batch_size x 3 x 384 x 384`, in out PatchGAN discriminator we have 3 sequential `3 x 3` conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchGAN(nn.Module):\n",
    "    def __init__(self, in_channels, n_features=64, n_layers=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        k_size = 4\n",
    "        p_size = 2\n",
    "        \n",
    "        seq = [nn.Conv2d(in_channels=in_channels, out_channels=n_features, kernel_size=k_size, padding=p_size, stride=2), nn.LeakyReLU(0.2, True)]\n",
    "        \n",
    "        f_mult = 1\n",
    "        f_mult_prev = 1\n",
    "        \n",
    "        for i in range(1, n_layers):\n",
    "            \n",
    "            f_mult_prev = f_mult\n",
    "            f_mult = min(2 ** i, 8)\n",
    "            \n",
    "            seq.append(nn.Conv2d(in_channels=f_mult_prev * n_features, out_channels=f_mult * n_features, kernel_size=k_size, padding=p_size, stride=2))\n",
    "            seq.append(nn.BatchNorm2d(f_mult * n_features))\n",
    "            seq.append(nn.LeakyReLU(0.2, True))\n",
    "\n",
    "        f_mult_prev = f_mult\n",
    "        f_mult = min(2 ** n_layers, 8)\n",
    "        \n",
    "        seq += [\n",
    "            nn.Conv2d(n_features * f_mult_prev, n_features * f_mult, kernel_size=k_size, stride=1, padding=p_size),\n",
    "            nn.BatchNorm2d(n_features * f_mult),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]\n",
    "\n",
    "        seq += [nn.Conv2d(n_features * f_mult, 1, kernel_size=k_size, stride=1, padding=p_size)]  # output 1 channel prediction map\n",
    "        self.model = nn.Sequential(*seq)\n",
    "\n",
    "    \n",
    "    def forward(self, x, label):\n",
    "        \n",
    "        x = torch.cat((x, label), dim=1)\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = PatchGAN(in_channels=3).to(device)\n",
    "#D2 = PatchGAN(in_channels=3).to(device)\n",
    "\n",
    "# summary(D, [(1, 384, 384), (2, 384, 384)])\n",
    "summary(D, [(1, image_size[0], image_size[1]), (2, image_size[0], image_size[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = UNet(in_channels=1, out_channels=2).to(device)\n",
    "#G2 = UNet(in_channels=2, out_channels=1).to(device)\n",
    "\n",
    "# summary(G, (1, 384, 384))\n",
    "summary(G, (1, image_size[0], image_size[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer <a class=\"anchor\" id=\"training\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer: \n",
    "    def __init__(self, G, D, device, batch_size = 64, lr=3e-4, discriminator_to_generator_training_rate = 2, plot_rate=1):\n",
    "        \n",
    "        self.G = G\n",
    "        self.D = D\n",
    "        \n",
    "        self.L1_G_loss = nn.L1Loss()\n",
    "        self.G_loss = nn.BCEWithLogitsLoss()\n",
    "        self.D_loss = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "        self.G_optim = torch.optim.Adam(params=G.parameters(), lr=lr)\n",
    "        self.D_optim = torch.optim.Adam(params=D.parameters(), lr=lr)\n",
    "\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.loss_G_per_epoch = []\n",
    "        self.loss_D_per_epoch = []\n",
    "        self.loss_D_real_per_epoch = []\n",
    "        self.loss_D_fake_per_epoch = []\n",
    "        \n",
    "        self.loss_G_history = []\n",
    "        self.loss_D_history = []\n",
    "        self.loss_D_real_history = []\n",
    "        self.loss_D_fake_history = []\n",
    "        \n",
    "        self.k = discriminator_to_generator_training_rate\n",
    "        self.device = device\n",
    "        \n",
    "        self.plot_rate = plot_rate\n",
    "    \n",
    "    def train(self, dataloader, epoch):\n",
    "        for epoch in range(epoch):\n",
    "            self.loss_G_history.append([])\n",
    "            self.loss_D_history.append([])\n",
    "            self.loss_D_real_history.append([])\n",
    "            self.loss_D_fake_history.append([])\n",
    "            \n",
    "            print(f'EPOCH: {epoch + 1}')\n",
    "            for i, (images, targets) in enumerate(tqdm(dataloader)):\n",
    "                self._train_discriminator(images, targets)\n",
    "                \n",
    "                if (i + 1) % self.k == 0:\n",
    "                    self._train_generator(images, targets)\n",
    "    \n",
    "            self.loss_G_per_epoch.append(np.mean(self.loss_G_history[-1]))\n",
    "            self.loss_D_per_epoch.append(np.mean(self.loss_D_history[-1]))\n",
    "            self.loss_D_real_per_epoch.append(np.mean(self.loss_D_real_history[-1]))\n",
    "            self.loss_D_fake_per_epoch.append(np.mean(self.loss_D_fake_history[-1]))\n",
    "            \n",
    "            if (epoch + 1) % self.plot_rate == 0:\n",
    "                self._plot_epoch_stats(epoch)\n",
    "                self._plot_fake_images(images, targets)\n",
    "            self._plot_stats\n",
    "\n",
    "    \n",
    "    def _train_generator(self, inputs, targets):\n",
    "        \n",
    "        self.G_optim.zero_grad()\n",
    "        \n",
    "        self.G.train()\n",
    "        self.D.eval()\n",
    "        \n",
    "        l = 1\n",
    "        \n",
    "        fake_targets = self.G(inputs)\n",
    "        \n",
    "        predictions = self.D(inputs, fake_targets)\n",
    "        fake_labels = torch.zeros(*predictions.shape,  device=self.device)\n",
    "        \n",
    "        L1_loss = self.L1_G_loss(fake_targets, targets)\n",
    "        BCE_loss = self.G_loss(predictions, fake_labels)\n",
    "        loss_g = BCE_loss + l * L1_loss\n",
    "        self.loss_G_history[-1].append(loss_g.item())\n",
    "        loss_g.backward()\n",
    "        self.G_optim.step()\n",
    "                \n",
    "    \n",
    "    def _train_discriminator(self, inputs, real_targets):\n",
    "        self.D_optim.zero_grad()\n",
    "        \n",
    "        self.G.eval()\n",
    "        self.D.train()\n",
    "        \n",
    "        # train on real images\n",
    "        \n",
    "        real_predictions = self.D(inputs, real_targets)\n",
    "        real_label = torch.ones(*real_predictions.shape,  device=self.device)\n",
    "\n",
    "        real = self.D_loss(real_predictions, real_label)\n",
    "        \n",
    "        \n",
    "        # train on fake images\n",
    "                \n",
    "        fake_targets = self.G(inputs)\n",
    "        fake_predictions = self.D(inputs, fake_targets.detach())\n",
    "        fake_label = torch.zeros(*fake_predictions.shape, device=self.device)\n",
    "\n",
    "        fake = self.D_loss(fake_predictions, fake_label)\n",
    "        \n",
    "        loss_d = real + fake\n",
    "        \n",
    "        self.loss_D_history[-1].append(loss_d.item())\n",
    "        self.loss_D_real_history[-1].append(real.item())\n",
    "        self.loss_D_fake_history[-1].append(fake.item())\n",
    "\n",
    "        loss_d.backward()\n",
    "        self.D_optim.step()\n",
    "        \n",
    "    def _plot_fake_images(self, images, targets, nrow=8):\n",
    "        \"\"\"\n",
    "        Showing the generator's results\n",
    "        \"\"\"\n",
    "        \n",
    "        self.G.eval()\n",
    "                \n",
    "        fake = self.G(images)\n",
    "        \n",
    "        to_show = lab_to_rgb(images, fake, device=self.device)\n",
    "        to_show_real = lab_to_rgb(images, targets, device=self.device)\n",
    "        a = fake[:, 0, :, :].unsqueeze(1).expand(to_show.shape)\n",
    "        b = fake[:, 1, :, :].unsqueeze(1).expand(to_show.shape)\n",
    "        grid = torchvision.utils.make_grid(torch.cat([images.expand(to_show.shape), a, b, to_show, to_show_real], dim=0), nrow=8, padding=1, scale_each=True)\n",
    "\n",
    "        fig = plt.figure(figsize=(16,8))\n",
    "        plt.imshow(grid.cpu().permute(1,2,0))\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "    def _plot_stats(self):\n",
    "        \"\"\"\n",
    "        Plotting stats of history training\n",
    "        \"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(10, 4))\n",
    "        sns.lineplot(self.loss_D_per_epoch, label=\"discriminator\", ax=axes[0][0])\n",
    "        sns.lineplot(self.loss_G_per_epoch, label=\"generator\", ax=axes[0][1])\n",
    "        \n",
    "        sns.lineplot(self.loss_D_real_per_epoch, label=\"real\", ax=axes[1][0])\n",
    "        sns.lineplot(self.loss_D_fake_per_epoch, label=\"fake\", ax=axes[1][1])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "    def _plot_epoch_stats(self, epoch):\n",
    "        \"\"\"\n",
    "        Plotting stats of history training\n",
    "        \"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(10, 4))\n",
    "        sns.lineplot(self.loss_D_history[epoch], label=\"discriminator\", ax=axes[0][0])\n",
    "        sns.lineplot(self.loss_G_history[epoch], label=\"generator\", ax=axes[0][1])\n",
    "        \n",
    "        sns.lineplot(self.loss_D_real_history[epoch], label=\"real\", ax=axes[1][0])\n",
    "        sns.lineplot(self.loss_D_fake_history[epoch], label=\"fake\", ax=axes[1][1])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def _plot_losses(self):\n",
    "        \"\"\"\n",
    "        Plot the generator and discriminator losses per epoch.\n",
    "        \"\"\"\n",
    "        epochs = range(1, len(self.loss_G_per_epoch) + 1)\n",
    "\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(epochs, self.loss_G_per_epoch, label='Generator loss', color='blue')\n",
    "        plt.plot(epochs, self.loss_D_per_epoch, label='Discriminator loss', color='red')\n",
    "        plt.title('Loss vs. Epoch')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(G, D, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(train_dl, epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer._plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.G"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elraang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
